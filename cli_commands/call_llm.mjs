// Full Path: /Users/rogerhill/Documents/GitHub/forgeborn-core/cli_commands/call_llm.mjs

import { graph } from "/Users/rogerhill/Documents/GitHub/forgeborn-core/agents/llmmanager/src/llmanager/index.mjs";
import { supabaseStore } from "/Users/rogerhill/Documents/GitHub/forgeborn-core/agents/llmmanager/src/utils/supabase-client.mjs";
import readline from "readline";

const [, , taskType, ...promptParts] = process.argv;
const prompt = promptParts.join(" ");

if (!taskType || !prompt) {
  console.error("‚ùå Unknown command or missing goal string.");
  process.exit(1);
}

console.log(`üß† Calling model for: ${taskType}`);
console.log(`üí¨ Prompt: ${prompt}`);

try {
  const result = await graph.invoke(
    { query: prompt },
    {
      store: supabaseStore,
      configurable: {
        assistant_id: "factory-observability",
        modelId: "openai/gpt-4o",               // ‚úÖ Updated model
        modelProvider: "openai",                // ‚úÖ Required for LangGraph routing
        approvalCriteria: "Supports proactive downtime mitigation.",
        rejectionCriteria: "Reactive-only, non-correlated approaches.",
      },
    }
  );

  console.log("\n‚úÖ Final Result:");
  console.dir(result, { depth: 10, colors: true });
} catch (err) {
  console.error("‚ùå LLM call failed:", err.message || err);
}
